{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:23:57.426163Z",
     "iopub.status.busy": "2022-11-07T18:23:57.425764Z",
     "iopub.status.idle": "2022-11-07T18:24:04.783024Z",
     "shell.execute_reply": "2022-11-07T18:24:04.776489Z",
     "shell.execute_reply.started": "2022-11-07T18:23:57.426083Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import transformers\n",
    "from transformers import (\n",
    "  AdamW,\n",
    "  BertConfig,\n",
    "  BertModel,\n",
    "  BertTokenizer)\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:04.789103Z",
     "iopub.status.busy": "2022-11-07T18:24:04.787723Z",
     "iopub.status.idle": "2022-11-07T18:24:04.803633Z",
     "shell.execute_reply": "2022-11-07T18:24:04.802146Z",
     "shell.execute_reply.started": "2022-11-07T18:24:04.789060Z"
    }
   },
   "outputs": [],
   "source": [
    "finegrained_sentiments_dict = {\n",
    "\"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
    "\"disgust\": [\"disgust\"],\n",
    "\"fear\": [\"fear\", \"nervousness\"],\n",
    "\"joy\": [\"joy\", \"amusement\", \"approval\", \"excitement\", \"gratitude\",  \"love\", \"optimism\", \"relief\", \"pride\", \"admiration\", \"desire\", \"caring\"],\n",
    "\"sadness\": [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\",  \"remorse\"],\n",
    "\"surprise\": [\"surprise\", \"realization\", \"confusion\", \"curiosity\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:04.808667Z",
     "iopub.status.busy": "2022-11-07T18:24:04.807189Z",
     "iopub.status.idle": "2022-11-07T18:24:05.890244Z",
     "shell.execute_reply": "2022-11-07T18:24:05.889127Z",
     "shell.execute_reply.started": "2022-11-07T18:24:04.808608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3-cs626-pos-tagging-week-of-8aug22.pdf\t\t\t   models\r\n",
      "'assignment-discussion-format-slide-POS-4sep22 (1).pptx'   modelStats.ods\r\n",
      " FineGrained-Emotion-Classification\t\t\t   POS\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:05.894704Z",
     "iopub.status.busy": "2022-11-07T18:24:05.894362Z",
     "iopub.status.idle": "2022-11-07T18:24:06.411272Z",
     "shell.execute_reply": "2022-11-07T18:24:06.410213Z",
     "shell.execute_reply.started": "2022-11-07T18:24:05.894667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples are 43410\n",
      "Number of dev examples are 5426\n",
      "Number of test examples are 5427\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"./data/full_dataset/\"\n",
    "train = {\"input\": [], \"labels\": []}\n",
    "dev = {\"input\": [], \"labels\": []}\n",
    "test = {\"input\": [], \"labels\": []}\n",
    "\n",
    "with open(DATA_DIR + \"train.tsv\") as file:\n",
    "    tsv_file = csv.reader(file, delimiter=\"\\t\") \n",
    "    for line in tsv_file:\n",
    "        train[\"input\"].append(line[0])\n",
    "        labels = line[1].split(\",\")\n",
    "        one_hot = [0 for i in range(28)]\n",
    "        for label in labels:\n",
    "            one_hot[int(label)] = 1\n",
    "        train[\"labels\"].append(one_hot)\n",
    "\n",
    "with open(DATA_DIR + \"dev.tsv\") as file:\n",
    "    tsv_file = csv.reader(file, delimiter=\"\\t\") \n",
    "    for line in tsv_file:\n",
    "        dev[\"input\"].append(line[0])\n",
    "        labels = line[1].split(\",\")\n",
    "        one_hot = [0 for i in range(28)]\n",
    "        for label in labels:\n",
    "            one_hot[int(label)] = 1\n",
    "        dev[\"labels\"].append(one_hot)\n",
    "\n",
    "with open(DATA_DIR + \"test.tsv\") as file:\n",
    "    tsv_file = csv.reader(file, delimiter=\"\\t\") \n",
    "    for line in tsv_file:\n",
    "        test[\"input\"].append(line[0])\n",
    "        labels = line[1].split(\",\")\n",
    "        one_hot = [0 for i in range(28)]\n",
    "        for label in labels:\n",
    "            one_hot[int(label)] = 1\n",
    "        test[\"labels\"].append(one_hot)\n",
    "        \n",
    "print(\"Number of train examples are {}\".format(len(train[\"input\"])))\n",
    "print(\"Number of dev examples are {}\".format(len(dev[\"input\"])))\n",
    "print(\"Number of test examples are {}\".format(len(test[\"input\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:06.413218Z",
     "iopub.status.busy": "2022-11-07T18:24:06.412869Z",
     "iopub.status.idle": "2022-11-07T18:24:06.640304Z",
     "shell.execute_reply": "2022-11-07T18:24:06.639214Z",
     "shell.execute_reply.started": "2022-11-07T18:24:06.413183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'labels'],\n",
      "    num_rows: 43410\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Creating higgingface datasets\n",
    "train_dataset = Dataset.from_dict(train)\n",
    "dev_dataset = Dataset.from_dict(dev)\n",
    "test_dataset = Dataset.from_dict(test)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:06.642373Z",
     "iopub.status.busy": "2022-11-07T18:24:06.641994Z",
     "iopub.status.idle": "2022-11-07T18:24:06.653482Z",
     "shell.execute_reply": "2022-11-07T18:24:06.652362Z",
     "shell.execute_reply.started": "2022-11-07T18:24:06.642333Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class LoadData(Dataset):\n",
    "    \"\"\"\n",
    "    Using this since dataloader expects map-style dataset objects\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, dataset, tokenizer, source_length):\n",
    "        \"\"\"\n",
    "        Initializes a Dataset class\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset object): Input Dataset\n",
    "            tokenizer (Tokenizer object): Transformer tokenizer\n",
    "            source_length (int): Max length of source text\n",
    "        \"\"\"\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataset\n",
    "        self.source_length = source_length\n",
    "        self.source_text = self.data[\"input\"]\n",
    "        self.target_labels = self.data[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        return input ids, attention masks and target ids\n",
    "        \n",
    "        \"\"\"\n",
    "        source_text = str(self.source_text[index])\n",
    "        target_label = self.target_labels[index]\n",
    "\n",
    "        # cleaning data so as to ensure data is in string type\n",
    "        source_text = \" \".join(source_text.split())\n",
    "\n",
    "        source = self.tokenizer.__call__(\n",
    "            [source_text],\n",
    "            max_length=self.source_length,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        target = torch.tensor(target_label)\n",
    "\n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        source_mask = source[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
    "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
    "            \"target\": target.squeeze().to(dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:34.663841Z",
     "iopub.status.busy": "2022-11-07T18:24:34.663437Z",
     "iopub.status.idle": "2022-11-07T18:24:34.683163Z",
     "shell.execute_reply": "2022-11-07T18:24:34.681670Z",
     "shell.execute_reply.started": "2022-11-07T18:24:34.663808Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, classifier, eval_dataloader, tokenizer, device, criterion):\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        steps = 0\n",
    "        for eval_batch in eval_dataloader:\n",
    "            y = eval_batch['target'].to(device, dtype = torch.float32)\n",
    "            ids = eval_batch['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = eval_batch['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            output = model(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask, \n",
    "            )\n",
    "            \n",
    "            output = classifier(output.pooler_output)\n",
    "            output = torch.sigmoid(output)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            steps += 1\n",
    "            if steps == 150: break  # evaluating only 1500 examples\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    print(\"Validation data loss is\", avg_loss)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "def train_(model, classifier, train_loader, valid_loader, device, tokenizer, optimizer, criterion, scheduler):\n",
    "    steps = 0\n",
    "    last_loss = 1000\n",
    "    \n",
    "    checkpoint_path = parameters[\"out_dir\"] + \"best_checkpoint/\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    \n",
    "    for epoch in range(parameters[\"epochs\"]):\n",
    "        print(\"Epoch: \", epoch)    \n",
    "        for batch in train_loader:\n",
    "            model.train()\n",
    "            classifier.train()\n",
    "            \n",
    "            y = batch[\"target\"].to(device, dtype=torch.float32)\n",
    "            ids = batch[\"source_ids\"].to(device, dtype=torch.long)\n",
    "            mask = batch[\"source_mask\"].to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask,\n",
    "            )\n",
    "            output = classifier(outputs.pooler_output)\n",
    "            output = torch.sigmoid(output)\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if steps % 200 == 0:\n",
    "                print(\"Train loss on {}th step is {}\".format(steps, loss.item()))\n",
    "            \n",
    "            if steps % 800 == 0:\n",
    "                model.eval()\n",
    "                print(\"Train loss on {}th step is {}\".format(steps, loss.item()))\n",
    "                loss = evaluate(model, classifier, valid_loader, tokenizer, device, criterion)\n",
    "                if loss < last_loss: # save model parameters\n",
    "                    print(\"saving model weights\")\n",
    "                    model.save_pretrained(checkpoint_path)\n",
    "                    tokenizer.save_pretrained(checkpoint_path)\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(checkpoint_path, \"optimizer.pt\"))\n",
    "                    torch.save(classifier.state_dict(), os.path.join(checkpoint_path, \"classifier.pt\"))\n",
    "                    last_loss = loss\n",
    "            steps += 1\n",
    "        scheduler.step()\n",
    "    \n",
    "    loss = evaluate(model, valid_loader, tokenizer)\n",
    "    if loss < last_loss: # save model parameters\n",
    "        print(\"saving model weights\")\n",
    "        model.save_pretrained(checkpoint_path)\n",
    "        torch.save(classifier.state_dict(), os.path.join(checkpoint_path, \"classifier.pt\"))\n",
    "        tokenizer.save_pretrained(checkpoint_path)\n",
    "        torch.save(optimizer.state_dict(), os.path.join(checkpoint_path, \"optimizer.pt\"))\n",
    "        last_loss = loss\n",
    "    \n",
    "    # save the last model weights\n",
    "    model.save_pretrained(parameters[\"out_dir\"])\n",
    "    torch.save(classifier.state_dict(), os.path.join(parameters[\"out_dir\"], \"classifier.pt\"))\n",
    "    tokenizer.save_pretrained(parameters[\"out_dir\"])\n",
    "    torch.save(optimizer.state_dict(), os.path.join(parameters[\"out_dir\"], \"optimizer.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:35.860527Z",
     "iopub.status.busy": "2022-11-07T18:24:35.860162Z",
     "iopub.status.idle": "2022-11-07T18:24:35.870737Z",
     "shell.execute_reply": "2022-11-07T18:24:35.869560Z",
     "shell.execute_reply.started": "2022-11-07T18:24:35.860495Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(parameters, train_dataset, valid_dataset):\n",
    "    cuda =  torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\") if cuda else torch.device(\"cpu\")\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(parameters[\"model\"])    \n",
    "    model = BertModel.from_pretrained(parameters[\"model\"])\n",
    "    classifier = nn.Linear(parameters[\"hidden_size\"], parameters[\"num_classes\"])\n",
    "    classifier = classifier.to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    params = list(model.parameters()) + list(classifier.parameters())\n",
    "    optimizer = AdamW(params, lr=parameters[\"lr\"], weight_decay=parameters[\"wd\"])\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)\n",
    "\n",
    "    train_obj = LoadData(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        parameters[\"max_source_length\"]\n",
    "    )\n",
    "\n",
    "    val_obj = LoadData(\n",
    "        valid_dataset,\n",
    "        tokenizer,\n",
    "        parameters[\"max_source_length\"]\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_obj, shuffle=True, batch_size=parameters[\"train_bs\"])\n",
    "    valid_loader = DataLoader(val_obj, shuffle=False, batch_size=parameters[\"val_bs\"])\n",
    "    \n",
    "    num_training_steps = parameters[\"epochs\"] * len(train_loader)\n",
    "    print(\"Training steps are\", num_training_steps)\n",
    "    \n",
    "    train_(model, classifier, train_loader, valid_loader, device, tokenizer, optimizer, criterion, scheduler)\n",
    "    \n",
    "    return model, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:36.691031Z",
     "iopub.status.busy": "2022-11-07T18:24:36.690247Z",
     "iopub.status.idle": "2022-11-07T18:24:36.698034Z",
     "shell.execute_reply": "2022-11-07T18:24:36.696842Z",
     "shell.execute_reply.started": "2022-11-07T18:24:36.690994Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\"model\": \"bert-base-cased\",  # model_type: t5-base/t5-large\n",
    "    \"train_bs\": 5,  # training batch size\n",
    "    \"val_bs\": 5,  # validation batch size\n",
    "    \"test_bs\": 15,\n",
    "    \"epochs\": 3,  # number of training epochs\n",
    "    \"lr\": 6e-4,  # learning rate\n",
    "    \"wd\": 0.0001,\n",
    "    \"max_source_length\": 512,  # max length of source text\n",
    "    \"SEED\": 42,\n",
    "    \"out_dir\": \"./\",\n",
    "    \"hidden_size\": 768,\n",
    "    \"num_classes\": 28}\n",
    "\n",
    "index_label = {0:\"admiration\", 1:\"amusement\", 2:\"anger\", 3:\"annoyance\", 4:\"approval\", 5:\"caring\", 6:\"confusion\",\n",
    "            7:\"curiosity\", 8:\"desire\", 9:\"disappointment\", 10:\"disapproval\", 11:\"disgust\", 12:\"embarrassment\",\n",
    "            13:\"excitement\", 14:\"fear\", 15:\"gratitude\", 16:\"grief\", 17:\"joy\", 18:\"love\", 19:\"nervousness\",\n",
    "            20:\"optimism\", 21:\"pride\", 22:\"realization\", 23:\"relief\", 24:\"remorse\", 25:\"sadness\",\n",
    "            26:\"surprise\", 27:\"neutral\"}\n",
    "label_list = list(index_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:42.511229Z",
     "iopub.status.busy": "2022-11-07T18:24:42.510545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c8d109266848e380f55e99fbb7c14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9335331bc343f0acf3e8c4335a49ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e601327371c4565b26ed926df365231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7875e5037645b9b23d3b42099a7c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/ashish/anaconda3/envs/nlp-626/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training steps are 26046\n",
      "Epoch:  0\n",
      "Train loss on 0th step is 0.7976132035255432\n",
      "Train loss on 0th step is 0.7976132035255432\n",
      "Validation data loss is 0.6173229622840881\n",
      "saving model weights\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:319] . unexpected pos 489305856 vs 489305744",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/nlp-626/lib/python3.9/site-packages/torch/serialization.py:379\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 379\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-626/lib/python3.9/site-packages/torch/serialization.py:604\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    603\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 604\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(parameters, train_dataset, valid_dataset)\u001b[0m\n\u001b[1;32m     31\u001b[0m num_training_steps \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining steps are\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_training_steps)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtrain_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, classifier\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mtrain_\u001b[0;34m(model, classifier, train_loader, valid_loader, device, tokenizer, optimizer, criterion, scheduler)\u001b[0m\n\u001b[1;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(checkpoint_path)\n\u001b[1;32m     71\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(checkpoint_path)\n\u001b[0;32m---> 72\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(classifier\u001b[38;5;241m.\u001b[39mstate_dict(), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     74\u001b[0m last_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-626/lib/python3.9/site-packages/torch/serialization.py:380\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    379\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m--> 380\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    381\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-626/lib/python3.9/site-packages/torch/serialization.py:259\u001b[0m, in \u001b[0;36m_open_zipfile_writer_buffer.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:319] . unexpected pos 489305856 vs 489305744"
     ]
    }
   ],
   "source": [
    "model, classifier = train_model(parameters, train_dataset, dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T14:48:07.646229Z",
     "iopub.status.busy": "2022-11-06T14:48:07.645793Z",
     "iopub.status.idle": "2022-11-06T14:49:50.212654Z",
     "shell.execute_reply": "2022-11-06T14:49:50.211692Z",
     "shell.execute_reply.started": "2022-11-06T14:48:07.646110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# compute metrics on test data\n",
    "def compute_metrics_allemotions(outputs, labels, label_list, index_label):\n",
    "    predictions = []\n",
    "    \n",
    "    for output in outputs:\n",
    "        output = [int(out > 0.6) for out in output]\n",
    "        predictions.append(output)\n",
    "    print(\"1st prediction\", predictions[0])\n",
    "    \n",
    "    confusion_matrix = {}\n",
    "    precisions, recalls, fscores = {}, {}, {}\n",
    "    for label in label_list:\n",
    "        confusion_matrix[label] = {\"TP\":0, \"FP\": 0, \"FN\": 0}\n",
    "        precisions[label], recalls[label], fscores[label] = 0, 0, 0\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        gt = labels[i]\n",
    "        for j, out in enumerate(gt):\n",
    "            pred = prediction[j]\n",
    "            if out == 0 and pred == 0: continue\n",
    "            elif out == 0 and pred == 1:\n",
    "                # FP found\n",
    "                confusion_matrix[index_label[j]][\"FP\"] += 1\n",
    "            elif out == 1 and pred == 0:\n",
    "                # FN found\n",
    "                confusion_matrix[index_label[j]][\"FN\"] += 1\n",
    "            elif out == 1 and pred == 1:\n",
    "                # TP found\n",
    "                confusion_matrix[index_label[j]][\"TP\"] += 1\n",
    "    \n",
    "    \n",
    "    for label in label_list:\n",
    "        precisions[label] = confusion_matrix[label][\"TP\"]/(confusion_matrix[label][\"TP\"] + confusion_matrix[label][\"FP\"] + 1e-4)\n",
    "        recalls[label] = confusion_matrix[label][\"TP\"]/(confusion_matrix[label][\"TP\"] + confusion_matrix[label][\"FN\"] + 1e-4)\n",
    "        fscores[label] = 2*precisions[label]*recalls[label]/(precisions[label]+recalls[label] + 1e-4)\n",
    "    \n",
    "    return precisions, recalls, fscores\n",
    "\n",
    "    \n",
    "\n",
    "def compute_test_outputs(model, classifier, test_dataloader, tokenizer, device, label_list, index_label):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        steps = 0\n",
    "        for test_batch in test_dataloader:\n",
    "            y = test_batch['target'].to(device, dtype = torch.float32)\n",
    "            ids = test_batch['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = test_batch['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            output = model(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask,\n",
    "            )\n",
    "            \n",
    "            output = classifier(output.pooler_output)\n",
    "            output = torch.sigmoid(output)\n",
    "            \n",
    "            predictions.extend(output.detach().cpu().numpy())\n",
    "            labels.extend(y.detach().cpu().numpy())\n",
    "            if steps == 5: break\n",
    "    \n",
    "    return predictions, labels\n",
    "    \n",
    "\n",
    "\n",
    "cuda =  torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\") if cuda else torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(parameters[\"model\"])\n",
    "model = BertModel.from_pretrained(parameters[\"model\"])\n",
    "classifier = nn.Linear(parameters[\"hidden_size\"], parameters[\"num_classes\"])\n",
    "classifier = classifier.to(device)\n",
    "model = model.to(device)\n",
    "test_obj = LoadData(\n",
    "        test_dataset,\n",
    "        tokenizer,\n",
    "        parameters[\"max_source_length\"]\n",
    "    )\n",
    "test_loader = DataLoader(test_obj, shuffle=True, batch_size=parameters[\"test_bs\"])\n",
    "predictions, labels = compute_test_outputs(model, classifier, test_loader, tokenizer, device, label_list, index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T14:55:01.674919Z",
     "iopub.status.busy": "2022-11-06T14:55:01.674218Z",
     "iopub.status.idle": "2022-11-06T14:55:02.253842Z",
     "shell.execute_reply": "2022-11-06T14:55:02.252626Z",
     "shell.execute_reply.started": "2022-11-06T14:55:01.674883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st prediction [0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision, Recall and Fscores for all labels are \n",
      "Emotion admiration: precision: 0.1666638889351844, recall: 0.0019841265904510736, fscore: 0.00391924317064396\n",
      "Emotion amusement: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion anger: precision: 0.03650586633440368, recall: 0.9898984899502575, fscore: 0.07040808300034321\n",
      "Emotion annoyance: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion approval: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion caring: precision: 0.0248985609572379, recall: 0.9999992592598079, fscore: 0.04858262529495087\n",
      "Emotion confusion: precision: 0.02819237095647004, recall: 0.9999993464056559, fscore: 0.054833374720585325\n",
      "Emotion curiosity: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion desire: precision: 0.01530235959988275, recall: 0.9999987951821745, fscore: 0.030140484066342395\n",
      "Emotion disappointment: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion disapproval: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion disgust: precision: 0.013651872473763663, recall: 0.03252029876398475, fscore: 0.019189199886623556\n",
      "Emotion embarrassment: precision: 0.006817762911041774, recall: 0.9999972973046017, fscore: 0.013541846286905712\n",
      "Emotion excitement: precision: 0.01843918758727533, recall: 0.9611641153746452, fscore: 0.03618051581936842\n",
      "Emotion fear: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion gratitude: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion grief: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion joy: precision: 0.029666481856154746, recall: 0.9999993788823733, fscore: 0.05761788103657609\n",
      "Emotion love: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion nervousness: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion optimism: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion pride: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion realization: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion relief: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion remorse: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion sadness: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion surprise: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Emotion neutral: precision: 0.0, recall: 0.0, fscore: 0.0\n",
      "Macro precision: 0.012147798271836222, Macro recall: 0.2494843252754983, Macro fscore: 0.01194333047436927\n"
     ]
    }
   ],
   "source": [
    "precisions, recalls, fscores = compute_metrics_allemotions(predictions, labels, label_list, index_label)\n",
    "print(\"Precision, Recall and Fscores for all labels are \")\n",
    "\n",
    "precision, recall, fscore = 0, 0, 0\n",
    "for label in label_list:\n",
    "    precision += precisions[label]\n",
    "    recall += recalls[label]\n",
    "    fscore += fscores[label]\n",
    "    print(\"Emotion {}: precision: {}, recall: {}, fscore: {}\".format(label, precisions[label], \n",
    "                                                                     recalls[label], fscores[label]))\n",
    "\n",
    "print(\"Macro precision: {}, Macro recall: {}, Macro fscore: {}\".format(precision/28, recall/28, fscore/28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
